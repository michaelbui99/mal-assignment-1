{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "Removal of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# lets see the columns\n",
    "col_vals = df.columns.values\n",
    "\n",
    "# now remove the columns\n",
    "cols_to_have = {\n",
    "    'id',\n",
    "    'name',\n",
    "    'host_id',\n",
    "    'host_name',\n",
    "    'neighbourhood_cleansed',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'room_type',\n",
    "    'price',\n",
    "    'minimum_nights',\n",
    "    'number_of_reviews',\n",
    "    'last_review',\n",
    "    'review_scores_rating',\n",
    "    'review_scores_accuracy',\n",
    "    'review_scores_cleanliness',\n",
    "    'review_scores_checkin',\n",
    "    'review_scores_communication',\n",
    "    'review_scores_location',\n",
    "    'review_scores_value',\n",
    "    'reviews_per_month',\n",
    "    'calculated_host_listings_count',\n",
    "    'availability_365'\n",
    "}\n",
    "\n",
    "col_vals_set = {val for val in col_vals}\n",
    "\n",
    "col_to_remove = col_vals_set.difference(cols_to_have)\n",
    "\n",
    "df.drop(col_to_remove, axis=1)\n",
    "\n",
    "# and lets check it out\n",
    "df = df.drop(list(col_to_remove), axis=1)\n",
    "\n",
    "df.columns.values\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "\n",
    "Next we have to handle missing values. Remove all rows where `number_of_reviews = 0`. If there are still missing values, remove the rows that contain them so you have a data set with no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = df[df['number_of_reviews']!=0]\n",
    "df = df.dropna()\n",
    "display(df.describe())\n",
    "display(df.head(20))\n",
    "display(df['neighbourhood_cleansed'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "\n",
    "Fix the `neighbourhood_cleansed` values (some are missing 'æ ø å'), and if necessary change the price to DKK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "exchange_rate = 6.96 # current exchange rate\n",
    "\n",
    "df['price_DKK'] = 0\n",
    "\n",
    "def usd_to_dkk(price_usd):\n",
    "    price_usd = float(price_usd.strip('$').replace(',', ''))\n",
    "    return price_usd * exchange_rate\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    price_usd = row['price']\n",
    "    price_dkk = usd_to_dkk(price_usd)\n",
    "    df.at[index, 'price_DKK'] = price_dkk\n",
    "\n",
    "df['price_DKK'] = df['price'].apply(usd_to_dkk)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df['neighbourhood_cleansed'] = df['neighbourhood_cleansed'].replace('Nrrebro','Nørrebro')\n",
    "df['neighbourhood_cleansed'] = df['neighbourhood_cleansed'].replace('sterbro','Østerbro')\n",
    "df['neighbourhood_cleansed'] = df['neighbourhood_cleansed'].replace('Amager st','Amager Øst')\n",
    "df['neighbourhood_cleansed'] = df['neighbourhood_cleansed'].replace('Brnshj-Husum','Brønshøj-Husum')\n",
    "df['neighbourhood_cleansed'] = df['neighbourhood_cleansed'].replace('Vanlse','Vanløse')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "\n",
    "Create a fitting word cloud based on the `name` column. Feel free to remove non-descriptive stop words (e.g. since this is about Copenhagen, perhaps the word 'Copenhagen' is redundant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=['Copenhagen']).generate(str(df['name'].values))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5\n",
    "\n",
    "Since data science is so much fun, provide a word cloud of the names of the hosts, removing any names of non-persons. Does this more or less correspond with the distribution of names according to [Danmarks Statistik](https://www.dst.dk/da/Statistik/emner/borgere/navne/navne-i-hele-befolkningen)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "wc = WordCloud(width=800, height=400, background_color='white').generate(str(df['host_name'].values))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\n",
    "\n",
    "Create a new column using bins of price. Use 11 bins, evenly distributed but with the last bin $> 10,000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 10000*exchange_rate, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 \n",
    "\n",
    "Using non-scaled versions of latitude and longitude, plot the listings data on a map. Use the newly created price bins as a color parameter. Also, create a plot (i.e. another plot) where you group the listings with regard to the neighbourhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "which_bin = np.digitize(df.loc[:,\"price_DKK\"], bins=bins).reshape(-1,1)\n",
    "which_bin_df = pd.DataFrame(which_bin, columns=['price_bin_interval'])\n",
    "df = df.assign(price_bin=which_bin)\n",
    "\n",
    "df['price_bin_interval'] = pd.cut(df['price_DKK'], bins)\n",
    "\n",
    "display(df.head())\n",
    "norm = matplotlib.colors.Normalize(vmin=min(bins), vmax=max(bins), clip=True)\n",
    "\n",
    "colormap = plt.cm.get_cmap('cool', len(bins)-1)\n",
    "df[which_bin_df.isnull().values]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['longitude'], df['latitude'], c= df['price_bin_interval'].cat.codes, cmap=colormap)\n",
    "plt.colorbar(label='Price Range')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "neighborhood_counts = df['neighbourhood_cleansed'].value_counts()\n",
    "neighborhood_counts.plot(kind='bar', figsize=(10, 6))\n",
    "plt.xlabel('Neighborhood')\n",
    "plt.ylabel('Number of listings')\n",
    "plt.title('Number of listings based on neighborhood')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n",
    "\n",
    "Create boxplots where you have the neighbourhood on the x-axis and price on the y-axis. What does this tell you about the listings in Copenhagen? Keep the x-axis as is and move different variables into the y-axis to see how things are distributed between the neighborhoods to create different plots (your choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "dfn = df.groupby('neighbourhood_cleansed')\n",
    "ax = dfn.boxplot(column='price_DKK',layout=(1,11), figsize=(18,7),whis=3,showfliers=False)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9\n",
    "\n",
    "Create a bar chart of the hosts with the top ten most listings. Place host id on the x-axis and the count of listings on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "dfh = df.groupby(['host_id']).size().sort_values(ascending=False)[:10]\n",
    "display(df)\n",
    "sns.barplot(x=dfh.index,y=dfh.values)\n",
    "plt.xticks(rotation=70)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10\n",
    "\n",
    "Do a descriptive analysis of the neighborhoods. Include information about room type in the analysis as well as one other self-chosen feature. The descriptive analysis should contain mean/average, mode, median, standard deviation/variance, minimum, maximum and quartiles.\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[['id','room_type', 'neighbourhood_cleansed', 'review_scores_rating']]\n",
    "grouped_data = filtered_df.groupby(['neighbourhood_cleansed', 'room_type']).describe()\n",
    "display(grouped_data['review_scores_rating'])\n",
    "\n",
    "mean_ratings = grouped_data['review_scores_rating']['mean'].reset_index()\n",
    "\n",
    "x_labels = mean_ratings.apply(lambda row: f\"{row['neighbourhood_cleansed']} - {row['room_type']}\", axis=1)\n",
    "\n",
    "plt.bar(x_labels,mean_ratings['mean'])\n",
    "plt.xlabel('Neighborhood - Room Type')\n",
    "plt.ylabel('Mean review score ratings')\n",
    "plt.title('Mean Review Scores Rating by Neighbourhood and Room Type')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11\n",
    "\n",
    "Supply a list of the top 10 highest rated listings and visualize them on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "df_sorted = df.sort_values(by='review_scores_rating', ascending=False)\n",
    "top_10_listings = df_sorted.head(10)\n",
    "\n",
    "top_10_listings_filtered = top_10_listings[['id', 'name','review_scores_rating', 'latitude', 'longitude']]\n",
    "\n",
    "display(top_10_listings_filtered)\n",
    "\n",
    "top_10_listings_map = folium.Map(location=[top_10_listings_filtered.iloc[0, 3], top_10_listings_filtered.iloc[0, 4]], zoom_start=10)\n",
    "\n",
    "# Add markers for the top 10 listings\n",
    "for index, row in top_10_listings_filtered.iterrows():\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    name = row['name']\n",
    "    folium.Marker(\n",
    "            location=[df.at[index, 'latitude'], df.at[index, 'longitude']],\n",
    "            popup=f\"{df.at[index, 'name']} - Rating: {df.at[index, 'review_scores_rating']}\",\n",
    "        ).add_to(top_10_listings_map)\n",
    "\n",
    "display(top_10_listings_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12\n",
    "Now, use any preprocessing and feature engineering steps that you find relevant before proceeding (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n",
    "features = df.loc[:,'room_type']\n",
    "features2 = df.loc[:,'neighbourhood_cleansed']\n",
    "\n",
    "df1 = df.drop(['host_name','neighbourhood_cleansed', 'name', 'price', 'room_type', 'last_review','id'\n",
    "               ,'review_scores_accuracy','latitude', 'longitude', 'review_scores_cleanliness','review_scores_checkin','review_scores_communication',\n",
    "               'review_scores_location','review_scores_value'], axis=1)\n",
    "\n",
    "display(df1.head())\n",
    "\n",
    "df1 = df1.join(pd.get_dummies(features))\n",
    "df1 = df1.join(pd.get_dummies(features2))\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "display(df1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13\n",
    "\n",
    "Create another new column, where the price is divided into two categories: \"expensive\" listings defined by all listings with a price higher than the median price, and \"affordable\" listings defined by all listings with a price equal to or below the median price. You can encode the affordable listings as \"0\" and the expensive ones as \"1\". All listings should now have a classification indicating either expensive listings (1) or affordable listings (0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "median = df1['price_DKK'].median()\n",
    "std = df1['price_DKK'].std()\n",
    "df1.loc[(df1['price_DKK'] - median).abs() > std,'price_DKK'] = np.nan\n",
    "df1['price_DKK'].fillna(median, inplace=True)\n",
    "\n",
    "\n",
    "df1['price_classification'] = 0\n",
    "df1.loc[df1['price_DKK'] > median, 'price_classification'] = 1\n",
    "df1.head()\n",
    "df1.describe()\n",
    "\n",
    "df1 = df1[df1['number_of_reviews'] > 150]\n",
    "df1 = df1[df1['availability_365'] > 5]\n",
    "df1 = df1[df1['review_scores_rating'] > 0]\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14\n",
    "\n",
    "Based on self-chosen features, develop a Naïve Bayes and k-Nearest Neighbor model to determine whether a rental property should be classified as 0 or 1. Remember to divide your data into training data and test data. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "y = df1['price_classification']\n",
    "df2 = df1.drop(['price_classification', 'price_bin_interval', 'price_bin'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df2,y, random_state=10)\n",
    "\n",
    "# X_train.info()\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "nb.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train,Y_train)\n",
    "\n",
    "print(knn.score(X_test.values, Y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15\n",
    "Try to come up with a final conclusion to the Airbnb-Copenhagen assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It has to be concluded that Naive Bayes is a better fit for this data set with a high level of accuracy for the Airbnb-Copenhagen data. This is due to the fact that this model is data-driven which meant that we had to clean the data throughly by removing noise and outliers before proceeding in order to get a high accuracy. \n",
    "\n",
    "As for K-Nearest Neighbour, on the other hand, it did not have such a high score as NB. Therefore, this means that this solution is not as good. Regarding the complexity of the 2 algorithms, NB is much less complex than K-Nearest Neighbor which means that it can be trained to be used more quickly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
